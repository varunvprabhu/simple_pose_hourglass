{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the necessary libraries\n",
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import imageio\n",
    "import h5py\n",
    "import tables\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import functools\n",
    "from functools import reduce\n",
    "import cv2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this ensures the program can use all the gpu resources it can get\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all dataset images are resized to 256x256 and stored in an hdf5 file so that the data pipeline is not throttled \n",
    "#while reading from the disk. \n",
    "\n",
    "hdf5_path = \"../data/image_mpii_data.hdf5\"\n",
    "hdf5_pose_path = \"../data/pose_raw.hdf5\"\n",
    "\n",
    "hdf5_file = tables.open_file(hdf5_path, mode='r')\n",
    "hdf5_pose_file = tables.open_file(hdf5_pose_path, mode='r')\n",
    "\n",
    "pose_images = hdf5_file.root.pose_images[:,:,:,:]\n",
    "pose_data = hdf5_pose_file.root.pose_stick[:,:,:,:]\n",
    "\n",
    "batch_size = 16\n",
    "number_of_images = pose_images.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(number_of_images) + \" \" + str(pose_data.shape[0]))\n",
    "number_train_images = 25936 #90% of whole set\n",
    "number_test_images = 2800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize weights\n",
    "def weight_initializer(weight_input, output_channel_size, filter_size): #, layer_num\n",
    "    \n",
    "    _, rows, columns, input_channel_size = [i.value for i in weight_input.get_shape()]\n",
    "    \n",
    "    weight_shape = [filter_size,filter_size,input_channel_size,output_channel_size]\n",
    "\n",
    "    weight_output = tf.Variable(tf.contrib.layers.xavier_initializer(uniform = False)(weight_shape))\n",
    "    \n",
    "    #weight_output = tf.get_variable(shape = weight_shape, dtype=tf.float32, \n",
    "                                    #initializer = tf.contrib.layers.xavier_initializer(uniform = False)) \n",
    "    #name = \"weight-\" + str(layer_num),\n",
    "    \n",
    "    return weight_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolution block \n",
    "def conv2d(block_input, num_filters, filter_size = 1, stride_length = 1): #, layer_num\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size) #, layer_num\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    block_output = tf.nn.conv2d(block_input,init_weights,strides,padding='VALID')\n",
    "    \n",
    "    return block_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_bn_relu(block_input, num_filters, filter_size = 1, stride_length = 1): #, layer_num\n",
    "    \n",
    "    init_weights = weight_initializer(block_input, num_filters, filter_size) #, layer_num\n",
    "    strides = [1,stride_length,stride_length,1]\n",
    "    \n",
    "    block_output = tf.nn.conv2d(block_input,init_weights,strides,padding='VALID')\n",
    "    normalized = tf.contrib.layers.batch_norm(block_output, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    \n",
    "    return normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(block_input, num_filters):\n",
    "    norm_1 = tf.contrib.layers.batch_norm(block_input, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    conv_1 = conv2d(norm_1, int(num_filters/2), 1, 1)\n",
    "    norm_2 = tf.contrib.layers.batch_norm(conv_1, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    pad = tf.pad(norm_2, np.array([[0,0],[1,1],[1,1],[0,0]]))\n",
    "    conv_2 = conv2d(pad, int(num_filters/2), 3, 1)\n",
    "    norm_3 = tf.contrib.layers.batch_norm(conv_2, 0.9, epsilon=1e-5, activation_fn = tf.nn.relu)\n",
    "    conv_3 = conv2d(norm_3, int(num_filters), 1, 1)\n",
    "    \n",
    "    return conv_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skip_layer(block_input, num_filters):\n",
    "    \n",
    "    if (block_input.get_shape()[3] == num_filters):\n",
    "        return block_input\n",
    "    else:\n",
    "        conv = conv2d(block_input, num_filters,1,1)\n",
    "        return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual(block_input, num_filters):\n",
    "    conv = conv_block(block_input, num_filters)\n",
    "    skip = skip_layer(block_input, num_filters)\n",
    "    \n",
    "    return(tf.add_n([conv,skip]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourglass_unit(input_data, reduction_factor, num_filters):\n",
    "    up_1 = residual(input_data, num_filters)\n",
    "    low = tf.contrib.layers.max_pool2d(input_data, [2,2],[2,2], 'VALID')\n",
    "    low_1 = residual(low, num_filters)\n",
    "    \n",
    "    if reduction_factor > 0:\n",
    "        low_2 = hourglass_unit(low_1, reduction_factor - 1, num_filters)\n",
    "    else:\n",
    "        low_2 = residual(low_1, num_filters)\n",
    "    \n",
    "    low_3 = residual(low_2, num_filters)\n",
    "    up_sample = tf.image.resize_nearest_neighbor(low_3, tf.shape(low_3)[1:3]*2)\n",
    "    return tf.add_n([up_1, up_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hourglass_model(input_data, num_blocks, num_filters, reduction_factor, train_model):\n",
    "    pad_1 = tf.pad(input_data, np.array([[0,0],[2,2],[2,2],[0,0]]))\n",
    "    conv_1 = conv2d(pad_1, 64,6,2)\n",
    "    res_1 = residual(conv_1, 128)\n",
    "    pool_1 = tf.contrib.layers.max_pool2d(res_1, [2,2], [2,2], padding= 'VALID')\n",
    "    res_2 = residual(pool_1, 128)\n",
    "    res_3 = residual(res_2, num_filters)\n",
    "    \n",
    "    x1 = [None] * num_blocks\n",
    "    x2 = [None] * num_blocks\n",
    "    x3 = [None] * num_blocks\n",
    "    x4 = [None] * num_blocks\n",
    "    x5 = [None] * num_blocks\n",
    "    x6 = [None] * num_blocks\n",
    "    sum_all = [None] * num_blocks\n",
    "    \n",
    "    x1[0] = hourglass_unit(res_3, reduction_factor, num_filters)\n",
    "    x2[0] = conv_bn_relu(x1[0], num_filters)\n",
    "    x3[0] = conv2d(x2[0], num_filters, 1, 1)\n",
    "    x4[0] = tf.layers.dropout(x3[0], rate = 0.1, training = train_model)\n",
    "    x5[0] = conv2d(x2[0], num_filters, 1, 1)\n",
    "    x6[0] = conv2d(x5[0], num_filters, 1, 1)\n",
    "    sum_all[0] = tf.add_n([x4[0], x6[0], res_3])\n",
    "    \n",
    "    for i in range(1, num_blocks - 1):\n",
    "        x1[i] = hourglass_unit(sum_all[i-1], reduction_factor, num_filters)\n",
    "        x2[i] = conv_bn_relu(x1[i], num_filters)\n",
    "        x3[i] = conv2d(x2[i], num_filters, 1, 1)\n",
    "        x4[i] = tf.layers.dropout(x3[i], rate = 0.1, training = train_model)\n",
    "        x5[i] = conv2d(x2[i], num_filters, 1, 1)\n",
    "        x6[i] = conv2d(x5[i], num_filters, 1, 1)\n",
    "        sum_all[i] = tf.add_n([x4[i], x6[i], sum_all[i-1]])\n",
    "    \n",
    "    x1[num_blocks - 1] = hourglass_unit(sum_all[num_blocks - 2], reduction_factor, num_filters)\n",
    "    x2[num_blocks - 1] = conv_bn_relu(x1[num_blocks - 1], num_filters)\n",
    "    x4[num_blocks - 1] = tf.layers.dropout(x2[num_blocks - 1], rate = 0.1, training = train_model)\n",
    "    x5[num_blocks - 1] = conv2d(x4[num_blocks - 1], 3, 1, 1)\n",
    "    final_output = tf.image.resize_nearest_neighbor(x5[num_blocks - 1], tf.shape(x5[num_blocks - 1])[1:3]*2)\n",
    "    return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Graph().as_default(),tf.Session() as sess:\n",
    "    \n",
    "    pose_img_input = tf.placeholder(tf.float32,shape=(batch_size,pose_images.shape[1],pose_images.shape[2],\n",
    "                                                      pose_images.shape[3]),name='pose_img_ip')\n",
    "    pose_stick_input = tf.placeholder(tf.float32,shape=(batch_size,pose_data.shape[1],pose_data.shape[2],\n",
    "                                                       pose_data.shape[3]),name='pose_data_ip')\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    pose_img_input = pose_img_input/255.0\n",
    "    \n",
    "    hg_output = hourglass_model(pose_img_input, 4, 256, 3, True) # true while training, false during inference\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    #calculate mse losses \n",
    "    pose_stick_input = pose_stick_input/255.0\n",
    "    total_loss = tf.losses.mean_squared_error(pose_stick_input, hg_output)\n",
    "    \n",
    "    ###################################################################################################################\n",
    "    #20180905 rate = 2.5e-4. losses fell from 580 to 370. 1 epoch trainin time ~ 1000secs\n",
    "    learning_rate = 2.5e-4\n",
    "    run = 1\n",
    "    training_step = tf.train.AdamOptimizer(learning_rate).minimize(total_loss)\n",
    "    num_epochs = 60\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    ###################################################################################################################\n",
    "    \n",
    "    restore_model = False\n",
    "    save_model = True\n",
    "    train_data = True\n",
    "    \n",
    "    #restore variable values. while saving the model further below, im only saving variable values and not the graph. \n",
    "    if(restore_model):\n",
    "        saver =  tf.train.Saver()  \n",
    "        saver.restore(sess,'../models/20180905/hg_12_4')\n",
    "    ###################################################################################################################\n",
    "    \n",
    "    if train_data:   \n",
    "        \n",
    "        num_minibatch = int(number_train_images/batch_size)\n",
    "        \n",
    "        for i in range(num_epochs+1):\n",
    "            print(\"epoch number is \", i)\n",
    "            batch_loss = 0.0\n",
    "\n",
    "            start_time = time.time()\n",
    "\n",
    "            for j in range(num_minibatch):\n",
    "                temp_content = pose_images[j*batch_size:batch_size*(j+1),:,:,:]\n",
    "                temp_pose_data = pose_data[j*batch_size:batch_size*(j+1),:,:,:]\n",
    "\n",
    "                _,tl = sess.run([training_step,total_loss], feed_dict={pose_img_input:temp_content, \n",
    "                                                                       pose_stick_input:temp_pose_data})\n",
    "                batch_loss += tl/num_minibatch\n",
    "\n",
    "            end_time = time.time()\n",
    "            print(\"total loss is \", batch_loss)\n",
    "            print(\"epoch time is \", (end_time - start_time))\n",
    "\n",
    "            #save the model without the graph.\n",
    "            if(save_model and i%3 == 0):\n",
    "                saver_2 = tf.train.Saver()  \n",
    "                saver_2.save(sess,\"../models/20180905/hg_\" + str(i) + \"_\" + str(run),write_meta_graph=False) \n",
    "    ###################################################################################################################\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
